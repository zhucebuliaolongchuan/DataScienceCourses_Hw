{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 1: Due Midnight, March 4th. 1/3 of a Grade Deducted for each day late"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: \n",
    "Chuan Long\n",
    "\n",
    "Student Netid: \n",
    "cl4076"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the main predictive modeling problem for Target is to identify pregnant customers and estimate the due date for pregnant customers to within a small time window, so that Target can send coupons timed to very specific stages of pregnancy and trigger them to buy more products. A decision tree model may be quite a good fit for this problem when Target needs to identify the pregnant customers. The following steps are the workflow a tree model induction.\n",
    "\n",
    "1. Finding and selecting informative attributes. In this case, just like Pole started his researches with the baby- shower registry. Women on the baby registry would buying larger quantities of unscented lotion around the beginning of their second trimester, something like that. So, we can collect these relative information as some particular categorical or numeric arrtibutes. This is the basis of a tree induction. What is more, we can use some clustering methods to get insight of the hidden attributes that may correlate to the problem but we don't think so. \n",
    "2. Measure the selected attributes. So, how's the informative attributes correlate to the problem we have to solve? One basic measure of attribute information is called information gain, which is based on a purity measure called information entropy. If the entropy of one paticular is close to zero, it means this attribute is highly correlate to the problem.\n",
    "3. Build(Train) the tree model recursively. Compute the Gain values based on the second step for all the attributes that we have selected at the first step, select the highest value and create a node for that attribute. And then, make a branch from this node for every value of the attribute. Assign all possible values of the attribute to branches. Follow the branch, we keep partitioning the dataset recursively, until all samples for a given node belong to the same class or there are no remaining attributes for furter partitioning or no samples left. Finally, we can have a tree model. So, if we want to predict whether a customer is pregnant or not, we just need to input the sample to the tree model, and get the probability of pregnancy when it comes to a leave.\n",
    "4. Evaluate the tree model. So, how's the performance of the tree model we generated? The model would be overfitting if we train the model with all the instances due to noised or outliers. And there are two approaches to avoid overfitting, which are prepruning and postpruning. For the prepruning, we halt the tree construction early - do not spilt a node if this would result in a bad performance(low accuracy). And for the postpruning, we remove branches from a 'fully grown' tree. What's more, we can adopt an appropraite loss function to evaluate a branch.\n",
    "\n",
    "Beyond identifying a pregnant customer, we also need to estimate the stages of pregnancy. For this particular problem, we can use K-nearest-neighbors methods to measure the distances between the instances. The reason is, similar customers would share similar behaviorial patterns, which means they have similar attributes(buy similar products). And the distances between them would less than those instances who are not in the same stages of pregnancyin a general way. So that we can send the coupons about hand-sanitizers and washcloths when they are close to their delivery date other than the coupons about unscented lotions. Because the KNN algorithm is a lazy learning method, and it is actually not a model.\n",
    "\n",
    "In a nutshell, my solution for this predictive model is:\n",
    "collect data -> find and select informative attributes -> measure the selected attributes -> create the branch for attributes and train the tree model recursively -> get the probability of pregancy for a customer -> use KNN to predict/estimate the stages of pregnancy(close to the delivery date or just at the beginning of the pregnancy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Dealing with messy data\n",
    "Not all data you will deal with is going to be clean. In fact, much of it will be very messy! For example, we have the HTML page that lists the contributors to Facebook's [osquery](https://github.com/facebook/osquery) project that is hosted on [Github.com](https://github.com). In this case, all we are interested in are the contributors and how many commits each of them has. Given the HTML page in `\"data/osquery_contributors.html\"` you will sift through tons of irrelevant data so that you can build a useful data structure.\n",
    "\n",
    "Notice that the first six (out of 59 total) contributors are named \"theopolis\", \"marpaia\", \"javuto\", \"jedi22\", \"unixist\", and \"mofarrell\". They have 553, 477, 104, 49, 30, 25 commits respectively.\n",
    "\n",
    "![Screenshot](images/osquery_contributors.png)\n",
    "\n",
    "To get a better of understanding of how this data is stored in the file, try searching through the raw data file for these usernames to look for any patterns. Your final dictionary should have 59 elements!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Turn this data into a Python dictionary called `contributors` where the keys are the contributor names and the values are the number of commits that each contributor has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'theopolis': '553', 'marpaia': '477', 'javuto': '104', 'jedi22': '49', 'unixist': '30', 'mofarrell': '25', 'sharvilshah': '23', 'lwhsu': '22', 'wxsBSD': '20', 'polachok': '14', 'zwass': '14', 'eastebry': '9', 'maus-': '9', 'vmauge': '8', 'astanway': '6', 'maclennann': '6', 'blakefrantz': '6', 'akshaydixi': '5', 'arirubinstein': '4', 'cdown': '4', 'deniszh': '3', 'achmiel': '3', 'brandt': '3', 'nlsun': '3', 'mimeframe': '3', 'mgoffin': '2', 'mathieuk': '2', 'ga2arch': '2', 'glensc': '2', 'jreese': '2', 'Anubisss': '2', 'timzimmermann': '2', 'jamesgpearce': '2', 'schettino72': '2', 'castrapel': '2', 'mlw': '2', 'apage43': '1', 'SimplyAhmazing': '1', 'quad': '1', 'yannick': '1', 'blackfist': '1', 'DavidGosselin': '1', 'ecin': '1', 'arubdesu': '1', 'yetanotherhacker': '1', 'rjeczalik': '1', 'larzconwell': '1', 'justintime32': '1', 'alex': '1', 'vlajos': '1', 'dreid': '1', 'kost': '1', 'mtmcgrew': '1', 'tburgin': '1', 'mark-ignacio': '1', 'shawndavenport': '1', 'jacknagz': '1', 'd0ugal': '1', 'stevenhilder': '1'}\n",
      "59\n"
     ]
    }
   ],
   "source": [
    "import re # you might find this package useful\n",
    "\n",
    "contributors = dict()\n",
    "\n",
    "# Read HTML File\n",
    "html_file = open('data/osquery_contributors.html', 'r', encoding = 'utf-8')\n",
    "raw_data = html_file.read()\n",
    "\n",
    "# Build the Regular Expression object\n",
    "pattern = re.compile(r'author=(\\w{0,10}.\\w{0,10})\">(\\d{1,3})')\n",
    "datas = pattern.findall(raw_data)\n",
    "\n",
    "# Load the date to the data structure used for store the result\n",
    "for data in datas:\n",
    "    contributors[data[0]] = data[1]\n",
    "\n",
    "# This line will print your dictionary for grading purposed. Do not remove this line!!!\n",
    "print(contributors)\n",
    "\n",
    "# Print the length of the results to verify the results\n",
    "print(len(contributors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54584.000000</td>\n",
       "      <td>2327.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042632</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>1.852777</td>\n",
       "      <td>0.210008</td>\n",
       "      <td>5.825610</td>\n",
       "      <td>-0.198040</td>\n",
       "      <td>-10.210786</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>86.569343</td>\n",
       "      <td>720.657592</td>\n",
       "      <td>0.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>0.067924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-181.923800</td>\n",
       "      <td>-187.615600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>174.625000</td>\n",
       "      <td>184.916700</td>\n",
       "      <td>84.285710</td>\n",
       "      <td>91.401920</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>37091.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            isbuyer     buy_freq    visit_freq  buy_interval   sv_interval  \\\n",
       "count  54584.000000  2327.000000  54584.000000  54584.000000  54584.000000   \n",
       "mean       0.042632     1.240653      1.852777      0.210008      5.825610   \n",
       "std        0.202027     0.782228      2.921820      3.922016     17.595442   \n",
       "min        0.000000     1.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000     1.000000      1.000000      0.000000      0.000000   \n",
       "50%        0.000000     1.000000      1.000000      0.000000      0.000000   \n",
       "75%        0.000000     1.000000      2.000000      0.000000      0.104167   \n",
       "max        1.000000    15.000000     84.000000    174.625000    184.916700   \n",
       "\n",
       "       expected_time_buy  expected_time_visit      last_buy    last_visit  \\\n",
       "count       54584.000000         54584.000000  54584.000000  54584.000000   \n",
       "mean           -0.198040           -10.210786     64.729335     64.729335   \n",
       "std             4.997792            31.879722     53.476658     53.476658   \n",
       "min          -181.923800          -187.615600      0.000000      0.000000   \n",
       "25%             0.000000             0.000000     18.000000     18.000000   \n",
       "50%             0.000000             0.000000     51.000000     51.000000   \n",
       "75%             0.000000             0.000000    105.000000    105.000000   \n",
       "max            84.285710            91.401920    188.000000    188.000000   \n",
       "\n",
       "       multiple_buy  multiple_visit     uniq_urls  num_checkins         y_buy  \n",
       "count  54584.000000    54584.000000  54584.000000  54584.000000  54584.000000  \n",
       "mean       0.006357        0.277444     86.569343    720.657592      0.004635  \n",
       "std        0.079479        0.447742     61.969765   1275.727306      0.067924  \n",
       "min        0.000000        0.000000     -1.000000      1.000000      0.000000  \n",
       "25%        0.000000        0.000000     30.000000    127.000000      0.000000  \n",
       "50%        0.000000        0.000000     75.000000    319.000000      0.000000  \n",
       "75%        0.000000        1.000000    155.000000    802.000000      0.000000  \n",
       "max        1.000000        1.000000    206.000000  37091.000000      1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Please note that this relative file path is work for my machine\n",
    "ads = pd.read_table('data/ads_dataset.tsv')\n",
    "# Shows the describe of the ads (not mandatory operation)\n",
    "ads.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getDfSummary(input_data):\n",
    "    # Use the describe() to get the mean, max, min, std, etc. attributes of the results\n",
    "    output_data = input_data.describe().transpose()\n",
    "    # Create two lists to record the corresponding values as required\n",
    "    number_nan = []\n",
    "    number_distinct = []\n",
    "    # Record the number_nan and number_distince for each attributes iteratively\n",
    "    for col in input_data.columns:\n",
    "        number_nan.append(len(input_data[col].index) - input_data[col].count())\n",
    "        number_distinct.append(len(input_data[col].unique()))\n",
    "    # Add the new attributes to the output dataframe\n",
    "    output_data['number_nan'] = number_nan\n",
    "    output_data['number_distinct'] = number_distinct\n",
    "    # I am not so sure for the style of output you asked for, so I just transpose the data frame, hope this is not a big deal\n",
    "    output_data = output_data.transpose()\n",
    "    return output_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 45.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "%timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['buy_freq']\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "output_data = getDfSummary(ads)\n",
    "missing_fields = []\n",
    "for col in output_data:\n",
    "    if output_data[col]['number_nan'] > 0:\n",
    "        missing_fields.append(col)\n",
    "print(missing_fields)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.651549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.686388</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.669298</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>65.741317</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255602</td>\n",
       "      <td>86.656180</td>\n",
       "      <td>721.848518</td>\n",
       "      <td>0.003024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.147955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.623555</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.239030</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>53.484622</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.436203</td>\n",
       "      <td>61.996711</td>\n",
       "      <td>1284.504018</td>\n",
       "      <td>0.054904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-187.615600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>318.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>803.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184.916700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.401920</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>37091.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_nan</th>\n",
       "      <td>0.0</td>\n",
       "      <td>52257.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_distinct</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5112.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13351.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>4570.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 isbuyer  buy_freq    visit_freq  buy_interval   sv_interval  \\\n",
       "count            52257.0       0.0  52257.000000       52257.0  52257.000000   \n",
       "mean                 0.0       NaN      1.651549           0.0      5.686388   \n",
       "std                  0.0       NaN      2.147955           0.0     17.623555   \n",
       "min                  0.0       NaN      1.000000           0.0      0.000000   \n",
       "25%                  0.0       NaN      1.000000           0.0      0.000000   \n",
       "50%                  0.0       NaN      1.000000           0.0      0.000000   \n",
       "75%                  0.0       NaN      2.000000           0.0      0.041667   \n",
       "max                  0.0       NaN     84.000000           0.0    184.916700   \n",
       "number_nan           0.0   52257.0      0.000000           0.0      0.000000   \n",
       "number_distinct      1.0       1.0     48.000000           1.0   5112.000000   \n",
       "\n",
       "                 expected_time_buy  expected_time_visit      last_buy  \\\n",
       "count                      52257.0         52257.000000  52257.000000   \n",
       "mean                           0.0            -9.669298     65.741317   \n",
       "std                            0.0            31.239030     53.484622   \n",
       "min                            0.0          -187.615600      0.000000   \n",
       "25%                            0.0             0.000000     19.000000   \n",
       "50%                            0.0             0.000000     52.000000   \n",
       "75%                            0.0             0.000000    106.000000   \n",
       "max                            0.0            91.401920    188.000000   \n",
       "number_nan                     0.0             0.000000      0.000000   \n",
       "number_distinct                1.0         13351.000000    189.000000   \n",
       "\n",
       "                   last_visit  multiple_buy  multiple_visit     uniq_urls  \\\n",
       "count            52257.000000       52257.0    52257.000000  52257.000000   \n",
       "mean                65.741317           0.0        0.255602     86.656180   \n",
       "std                 53.484622           0.0        0.436203     61.996711   \n",
       "min                  0.000000           0.0        0.000000     -1.000000   \n",
       "25%                 19.000000           0.0        0.000000     30.000000   \n",
       "50%                 52.000000           0.0        0.000000     75.000000   \n",
       "75%                106.000000           0.0        1.000000    155.000000   \n",
       "max                188.000000           0.0        1.000000    206.000000   \n",
       "number_nan           0.000000           0.0        0.000000      0.000000   \n",
       "number_distinct    189.000000           1.0        2.000000    207.000000   \n",
       "\n",
       "                 num_checkins         y_buy  \n",
       "count            52257.000000  52257.000000  \n",
       "mean               721.848518      0.003024  \n",
       "std               1284.504018      0.054904  \n",
       "min                  1.000000      0.000000  \n",
       "25%                126.000000      0.000000  \n",
       "50%                318.000000      0.000000  \n",
       "75%                803.000000      0.000000  \n",
       "max              37091.000000      1.000000  \n",
       "number_nan           0.000000      0.000000  \n",
       "number_distinct   4570.000000      2.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Place your code here\n",
    "import math\n",
    "new_ads = ads[pd.isnull(ads.buy_freq)]\n",
    "getDfSummary(new_ads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbuyer</th>\n",
       "      <th>buy_freq</th>\n",
       "      <th>visit_freq</th>\n",
       "      <th>buy_interval</th>\n",
       "      <th>sv_interval</th>\n",
       "      <th>expected_time_buy</th>\n",
       "      <th>expected_time_visit</th>\n",
       "      <th>last_buy</th>\n",
       "      <th>last_visit</th>\n",
       "      <th>multiple_buy</th>\n",
       "      <th>multiple_visit</th>\n",
       "      <th>uniq_urls</th>\n",
       "      <th>num_checkins</th>\n",
       "      <th>y_buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>54584.000000</td>\n",
       "      <td>2327.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "      <td>54584.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.042632</td>\n",
       "      <td>1.240653</td>\n",
       "      <td>1.852777</td>\n",
       "      <td>0.210008</td>\n",
       "      <td>5.825610</td>\n",
       "      <td>-0.198040</td>\n",
       "      <td>-10.210786</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>64.729335</td>\n",
       "      <td>0.006357</td>\n",
       "      <td>0.277444</td>\n",
       "      <td>86.569343</td>\n",
       "      <td>720.657592</td>\n",
       "      <td>0.004635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.202027</td>\n",
       "      <td>0.782228</td>\n",
       "      <td>2.921820</td>\n",
       "      <td>3.922016</td>\n",
       "      <td>17.595442</td>\n",
       "      <td>4.997792</td>\n",
       "      <td>31.879722</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>53.476658</td>\n",
       "      <td>0.079479</td>\n",
       "      <td>0.447742</td>\n",
       "      <td>61.969765</td>\n",
       "      <td>1275.727306</td>\n",
       "      <td>0.067924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-181.923800</td>\n",
       "      <td>-187.615600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>319.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>105.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>155.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>84.000000</td>\n",
       "      <td>174.625000</td>\n",
       "      <td>184.916700</td>\n",
       "      <td>84.285710</td>\n",
       "      <td>91.401920</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>37091.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_nan</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52257.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_distinct</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>295.000000</td>\n",
       "      <td>5886.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>15135.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>189.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>4628.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      isbuyer      buy_freq    visit_freq  buy_interval  \\\n",
       "count            54584.000000   2327.000000  54584.000000  54584.000000   \n",
       "mean                 0.042632      1.240653      1.852777      0.210008   \n",
       "std                  0.202027      0.782228      2.921820      3.922016   \n",
       "min                  0.000000      1.000000      0.000000      0.000000   \n",
       "25%                  0.000000      1.000000      1.000000      0.000000   \n",
       "50%                  0.000000      1.000000      1.000000      0.000000   \n",
       "75%                  0.000000      1.000000      2.000000      0.000000   \n",
       "max                  1.000000     15.000000     84.000000    174.625000   \n",
       "number_nan           0.000000  52257.000000      0.000000      0.000000   \n",
       "number_distinct      2.000000     11.000000     64.000000    295.000000   \n",
       "\n",
       "                  sv_interval  expected_time_buy  expected_time_visit  \\\n",
       "count            54584.000000       54584.000000         54584.000000   \n",
       "mean                 5.825610          -0.198040           -10.210786   \n",
       "std                 17.595442           4.997792            31.879722   \n",
       "min                  0.000000        -181.923800          -187.615600   \n",
       "25%                  0.000000           0.000000             0.000000   \n",
       "50%                  0.000000           0.000000             0.000000   \n",
       "75%                  0.104167           0.000000             0.000000   \n",
       "max                184.916700          84.285710            91.401920   \n",
       "number_nan           0.000000           0.000000             0.000000   \n",
       "number_distinct   5886.000000         348.000000         15135.000000   \n",
       "\n",
       "                     last_buy    last_visit  multiple_buy  multiple_visit  \\\n",
       "count            54584.000000  54584.000000  54584.000000    54584.000000   \n",
       "mean                64.729335     64.729335      0.006357        0.277444   \n",
       "std                 53.476658     53.476658      0.079479        0.447742   \n",
       "min                  0.000000      0.000000      0.000000        0.000000   \n",
       "25%                 18.000000     18.000000      0.000000        0.000000   \n",
       "50%                 51.000000     51.000000      0.000000        0.000000   \n",
       "75%                105.000000    105.000000      0.000000        1.000000   \n",
       "max                188.000000    188.000000      1.000000        1.000000   \n",
       "number_nan           0.000000      0.000000      0.000000        0.000000   \n",
       "number_distinct    189.000000    189.000000      2.000000        2.000000   \n",
       "\n",
       "                    uniq_urls  num_checkins         y_buy  \n",
       "count            54584.000000  54584.000000  54584.000000  \n",
       "mean                86.569343    720.657592      0.004635  \n",
       "std                 61.969765   1275.727306      0.067924  \n",
       "min                 -1.000000      1.000000      0.000000  \n",
       "25%                 30.000000    127.000000      0.000000  \n",
       "50%                 75.000000    319.000000      0.000000  \n",
       "75%                155.000000    802.000000      0.000000  \n",
       "max                206.000000  37091.000000      1.000000  \n",
       "number_nan           0.000000      0.000000      0.000000  \n",
       "number_distinct    207.000000   4628.000000      2.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the descirbe of the original data frame\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Explanation: As we can see before, when we delete the rows that do not contain the NaN values, the feature: buy_interval, expected_time_buy, multiply_buy, change dramatically, which indicates that this fields are correlate to the buy_freq perfectly. So, if a record contains missing values, it means that the values of these fields would be zero. And we can think of it in an intuitive way, which is, if the value of buy_freq for a customer is missing, it means this customer is not active, and the information of relative attributes should be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']\n"
     ]
    }
   ],
   "source": [
    "# Place your code here\n",
    "# Create a list to hold the binary variables\n",
    "binary_var = []\n",
    "for col in output_data:\n",
    "    # if the value of describe attribute 'number_distince' is 2, it means this value of this attrbute is binary\n",
    "    if output_data[col]['number_distinct'] == 2:\n",
    "        binary_var.append(col)\n",
    "print(binary_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
